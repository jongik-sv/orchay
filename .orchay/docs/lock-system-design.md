# 프로세스 간 명령어 실행 상태 공유 시스템 설계

## 문제 정의

여러 Claude Code 프로세스가 동시에 실행될 때, 특정 Task에 대해 어떤 명령어가 실행 중인지 서로 알아야 함.
- 충돌 방지: 같은 Task에 두 프로세스가 동시에 작업하지 않도록
- 작업 조율: 다른 프로세스가 실행 중인 작업은 건너뛰고 다른 작업 선택

---

# Part 1: 방법 분석

## 방법 1: 파일 기반 Lock 시스템

락 파일을 생성하여 실행 상태 표시.

```
.orchay/locks/
├── TSK-01-01.lock.json
├── TSK-02-03.lock.json
└── ...
```

| 장점 | 단점 |
|------|------|
| 별도 의존성 없음 | Race Condition 가능 |
| Git 친화적 (.gitignore 추가 가능) | 좀비 락 발생 (강제 종료 시) |
| 디버깅 용이 (파일 직접 확인) | 폴링 필요 (실시간 감지 불가) |
| 크로스 플랫폼 | 파일 쓰기 중 읽기 가능 |

---

## 방법 2: Serena MCP Memory

Serena의 `write_memory`, `read_memory`, `delete_memory` 활용.

| 장점 | 단점 |
|------|------|
| 이미 프로젝트에서 사용 중 | Claude 실행 필요 |
| 구조화된 API 제공 | 인스턴스 간 공유 불확실 |
| Claude 세션과 자연스럽게 통합 | 외부 도구에서 접근 불가 |

---

## 방법 3: SQLite 로컬 DB

단일 파일 DB에 락 정보 저장.

| 장점 | 단점 |
|------|------|
| ACID 트랜잭션으로 원자성 보장 | 네이티브 모듈 의존성 (better-sqlite3) |
| 복잡한 쿼리 가능 | Windows 빌드 이슈 가능 |
| WAL 모드로 동시 읽기/쓰기 지원 | 좀비 문제 동일 |

---

## 방법 4: Node.js IPC

Named Pipe로 중앙 락 매니저 구현.

| 장점 | 단점 |
|------|------|
| 실시간 이벤트 기반 | 서버/클라이언트 아키텍처 복잡 |
| 중앙에서 모든 락 관리 | 데몬이 항상 실행되어야 함 |
| 요청 순서대로 처리 | 매니저 죽으면 전체 마비 |

---

## 방법 5: OS 레벨 파일 락

`proper-lockfile` 등 OS flock/fcntl 기반 락.

| 장점 | 단점 |
|------|------|
| OS 커널 레벨에서 원자적 락 | 메타데이터 저장 어려움 |
| 프로세스 종료 시 자동 해제 | NFS에서 불안정 |
| Race Condition 없음 | Windows와 Unix 동작 차이 |

---

## 방법 6: Redis / 인메모리 DB

외부 Redis 서버 활용.

| 장점 | 단점 |
|------|------|
| 고성능 메모리 기반 | Redis 서버 설치 필요 |
| TTL로 자동 만료 (좀비 방지) | 로컬 도구에 과한 인프라 |
| Pub/Sub 실시간 알림 | 사용자 진입장벽 증가 |

---

## 비교 매트릭스

| 방법 | 구현 난이도 | 신뢰성 | 실시간 | 의존성 | 좀비 방지 | 추천도 |
|------|------------|--------|--------|--------|----------|--------|
| 파일 기반 | 쉬움 | 중간 | X | 없음 | PID 확인 | ★★★ |
| Serena MCP | 쉬움 | 불확실 | X | MCP | 수동 | ★★ |
| SQLite | 보통 | 높음 | X | 네이티브 | Heartbeat | ★★★ |
| Node IPC | 어려움 | 높음 | O | 없음 | 자동 | ★★ |
| OS 파일락 | 쉬움 | 높음 | X | npm | 자동 | ★★★★ |
| Redis | 어려움 | 높음 | O | 서버 | TTL | ★ |

---

## 권장안

### 1차 권장: 파일 기반 + Heartbeat

orchay의 파일 기반 철학과 일치. 추가 의존성 최소화.

### 2차 대안: OS 파일락 + 메타데이터 파일

- `.lock` 파일: proper-lockfile이 관리 (원자성, 자동 해제)
- `.meta` 파일: 명령어 정보 JSON 저장

### 3차 대안: SQLite + Heartbeat

대시보드에서 모든 진행 중 작업 표시 등 복잡한 쿼리 필요 시.

---

# Part 2: 파일 기반 락 시스템 상세 설계

## 락 파일 구조

```
.orchay/locks/
├── TSK-01-01.lock.json
├── TSK-02-03.lock.json
└── ...
```

### 락 파일 내용

| 필드 | 설명 | 예시 |
|------|------|------|
| taskId | Task 식별자 | "TSK-01-01" |
| command | 실행 중인 명령어 | "/wf:build" |
| pid | 프로세스 ID | 12345 |
| sessionId | 실행 고유 ID (UUID) | "550e8400-..." |
| startedAt | 시작 시간 (ISO 8601) | "2025-12-15T10:30:00.000Z" |
| heartbeatAt | 마지막 갱신 시간 | "2025-12-15T10:35:00.000Z" |
| timeout | 타임아웃 (ms) | 1800000 (30분) |

---

## Claude Code의 PID 동작

### 핵심 이해

```
터미널 1                          터미널 2
─────────────────────────────    ─────────────────────────────
claude (PID: 12345)              claude (PID: 67890)
  │                                │
  ├─ /wf:start  → 같은 PID         ├─ /wf:build → 같은 PID
  ├─ /wf:draft  → 같은 PID         └─ /wf:done  → 같은 PID
  └─ /wf:build  → 같은 PID
```

| 상황 | PID |
|------|-----|
| 같은 Claude 세션 내 슬래시 명령어 | **동일** |
| 다른 터미널에서 새 Claude 실행 | **다름** |
| Bash 도구로 외부 명령어 실행 | 자식 프로세스 (다른 PID) |

### 문제: 같은 세션에서 Ctrl+C 후 재실행

```
터미널 1 (PID: 12345)
─────────────────────────
10:00  /wf:build TSK-01-01  → 락 생성 (PID: 12345)
10:05  (사용자가 Ctrl+C로 중단)
10:06  /wf:build TSK-01-01  → 락 확인 → PID 12345 살아있음 → 충돌!
```

PID만으로는 같은 세션 내에서 이전 실행이 중단됐는지 구분 불가.

### 해결: 3가지 식별자 조합

| 식별자 | 역할 |
|--------|------|
| **PID** | 다른 터미널/프로세스 구분 |
| **sessionId** | 같은 프로세스 내 다른 실행 구분 (매번 새로 생성) |
| **Heartbeat** | 실제로 살아있는지 확인 (가장 중요) |

---

## 좀비 락 감지 방법 (3단계)

### 1단계: PID 생존 확인

`process.kill(pid, 0)`으로 프로세스 존재 여부 확인.
- 시그널 0은 실제로 시그널을 보내지 않고 존재만 확인
- 프로세스 종료됐으면 `ESRCH` 에러 발생

| 결과 | 의미 | 조치 |
|------|------|------|
| 성공 | 프로세스 살아있음 | 락 유효 |
| ESRCH | 프로세스 없음 | **좀비 → 삭제** |
| EPERM | 권한 없음 (존재함) | 락 유효 |

### 2단계: Heartbeat 확인

1분마다 `heartbeatAt` 필드 갱신. 3분 이상 갱신 안 되면 좀비로 판단.

**왜 필요한가?**
- PID는 OS가 재사용할 수 있음
- 이전 프로세스가 죽고 새 프로세스가 같은 PID를 받으면 오판 가능
- Heartbeat로 "정말 이 락을 건 프로세스가 살아있는지" 확인

| 설정 | 값 | 설명 |
|------|-----|------|
| HEARTBEAT_INTERVAL | 60초 | 갱신 주기 |
| HEARTBEAT_TIMEOUT | 180초 | 이 시간 초과 시 좀비 |

### 3단계: 절대 타임아웃

시작 후 30분(기본값) 초과 시 강제로 좀비 처리.

**왜 필요한가?**
- 무한 루프에 빠진 명령어 방지
- Heartbeat는 갱신되지만 실제로는 멈춰있는 경우 대비
- 최후의 안전장치

### 판단 우선순위 (흐름도)

```
PID 죽음?
  ├─ Yes → 즉시 좀비 (확실)
  └─ No ↓

Heartbeat 3분 초과?
  ├─ Yes → 좀비 의심 (PID 재사용 가능성)
  └─ No ↓

30분 타임아웃?
  ├─ Yes → 강제 좀비 (무한루프 방지)
  └─ No → 락 유효
```

### 좀비 감지 요약

| 감지 방법 | 확실성 | 감지 시점 | 용도 |
|----------|--------|----------|------|
| PID 확인 | ★★★★★ | 즉시 | 프로세스 종료 감지 |
| Heartbeat | ★★★★ | 3분 후 | PID 재사용 대비 |
| 타임아웃 | ★★★ | 30분 후 | 무한루프 방지 |

---

## 타임아웃 설정 가이드

명령어별로 예상 소요 시간에 맞게 타임아웃 설정.

| 명령어 | 권장 타임아웃 | 이유 |
|--------|-------------|------|
| `/wf:start` | 5분 | 단순 상태 변경 |
| `/wf:draft` | 30분 | 설계 문서 생성 |
| `/wf:build` | 60분 | TDD 구현, 가장 오래 걸림 |
| `/wf:review` | 20분 | 코드 리뷰 |
| `/wf:verify` | 30분 | 테스트 실행 |
| `/wf:done` | 5분 | 마무리 작업 |

---

## 락 매니저 동작 흐름

### 락 획득 시

```
1. 기존 락 파일 존재 확인
   ├─ 없음 → 새 락 생성
   └─ 있음 → 상태 확인
              ├─ active → 획득 실패 (이미 실행 중)
              └─ zombie → 삭제 후 새 락 생성

2. 락 파일 생성 (JSON)
   - taskId, command, pid, sessionId, startedAt, heartbeatAt

3. Heartbeat 타이머 시작 (1분 간격)
```

### 락 해제 시

```
1. Heartbeat 타이머 중지
2. 락 파일 삭제
```

### 락 확인 시 (다른 프로세스)

```
1. 락 파일 읽기
2. 상태 확인 (PID → Heartbeat → 타임아웃)
   ├─ active → 락 정보 반환
   └─ zombie → 파일 삭제, null 반환
```

---

## 사용 시나리오

### 시나리오 1: 정상 실행 및 완료

```
프로세스 A (터미널 1)
─────────────────────────────────────
10:00  /wf:build TSK-01-01
       → 락 획득 성공
       → TSK-01-01.lock.json 생성
10:01  → Heartbeat 갱신
10:02  → Heartbeat 갱신
...
10:15  → 작업 완료
       → 락 해제
       → TSK-01-01.lock.json 삭제
```

### 시나리오 2: 다른 프로세스가 같은 Task 시도

```
프로세스 A (터미널 1)          프로세스 B (터미널 2)
────────────────────────      ────────────────────────
10:00  /wf:build TSK-01-01
       → 락 획득
                              10:05  /wf:build TSK-01-01
                                     → 락 확인
                                     → active 상태
                                     → "이미 실행 중" 메시지
                                     → 다른 Task 선택
```

### 시나리오 3: 프로세스 강제 종료 후 재시도

```
프로세스 A (터미널 1)          프로세스 B (터미널 2)
────────────────────────      ────────────────────────
10:00  /wf:build TSK-01-01
       → 락 획득
10:02  (Ctrl+C 또는 크래시)
       → 락 파일 남아있음
                              10:05  /wf:build TSK-01-01
                                     → 락 확인
                                     → PID 확인 → 죽어있음
                                     → 좀비 락 삭제
                                     → 새 락 획득
                                     → 작업 진행
```

### 시나리오 4: Heartbeat 타임아웃

```
프로세스 A (터미널 1)          프로세스 B (터미널 2)
────────────────────────      ────────────────────────
10:00  /wf:build TSK-01-01
       → 락 획득
10:01  (네트워크 끊김 등으로 멈춤)
       → Heartbeat 갱신 안됨
                              10:05  /wf:build TSK-01-01
                                     → 락 확인
                                     → PID 살아있음
                                     → Heartbeat 3분+ 초과
                                     → 좀비 판정
                                     → 락 삭제 & 새 락 획득
```

---

## 결론

### 최종 권장 구성

**파일 기반 락 + PID + sessionId + Heartbeat**

| 요소 | 역할 |
|------|------|
| 락 파일 | 실행 상태 저장 및 공유 |
| PID | 다른 프로세스 구분 |
| sessionId | 같은 프로세스 내 재실행 구분 |
| Heartbeat | 실제 생존 확인 |
| 타임아웃 | 최후 안전장치 |

### orchay에 적합한 이유

1. **파일 기반 철학과 일치**: `.orchay/` 폴더 구조 활용
2. **추가 의존성 최소화**: 외부 DB나 서버 불필요
3. **디버깅 용이**: 락 파일을 직접 확인/삭제 가능
4. **크로스 플랫폼**: Windows/Mac/Linux 모두 동작

### 3단계 좀비 감지로 신뢰성 확보

```
PID 죽음 → 즉시 감지 (확실)
Heartbeat 초과 → 3분 후 감지 (PID 재사용 대비)
타임아웃 → 30분 후 강제 (무한루프 방지)
```

이 조합으로 거의 모든 좀비 락을 감지할 수 있습니다.
